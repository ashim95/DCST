{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-90325a47b1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/jiv/TF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "model_dir = tempfile.mkdtemp(dir='/home/jiv/TF')\n",
    "print(model_dir)\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved earlier\n",
      "Getting embedding matrix for vocubolory ...\n",
      "File is already present\n",
      "Getting features matrix for train and test data ...\n",
      "File is already present\n"
     ]
    }
   ],
   "source": [
    "# Parameters of fast text are\n",
    "size=350\n",
    "window=11\n",
    "min_n=2\n",
    "max_n=11\n",
    "epochs=80\n",
    "embedding_matrix, x_train, y_train, x_test, y_test = BuildFasttext(size,window,min_n,max_n,epochs)\n",
    "###########################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_strat, x_dev, y_strat, y_dev = train_test_split(x_train, y_train,test_size=0.20,random_state=0,stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping words to there dictionary index and getting vector corroponding to input words\n",
    "file_name=open(\"./data/compound_dic.pickle\",\"rb\")\n",
    "my_dic = pickle.load(file_name)\n",
    "train=pd.read_csv('./data/train.csv')\n",
    "test=pd.read_csv('./data/test.csv')\n",
    "x_train_temp=np.empty([len(train), 2], dtype=int)\n",
    "x_test_voc=np.empty([len(test), 2], dtype=int)\n",
    "for i in range(0,len(train)):\n",
    "    x_train_temp[i]=[my_dic.get(train.iloc[i,1]),my_dic.get(train.iloc[i,2])]\n",
    "for i in range(0,len(test)):\n",
    "    x_test_voc[i]=[my_dic.get(test.iloc[i,1]),my_dic.get(test.iloc[i,2])]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_voc, x_dev_voc, y_train_voc, y_dev_voc = train_test_split(x_train_temp, y_train,test_size=0.20,random_state=0,stratify=y_train)\n",
    "\n",
    "# Setting parameters for custom estimators\n",
    "########################################################################\n",
    "import tensorflow as tf\n",
    "my_batch_size=100\n",
    "my_num_epochs=75\n",
    "my_steps=(my_num_epochs * x_train_voc.shape[0])/my_batch_size\n",
    "# my_steps=2200\n",
    "VOC_size=len(my_dic)\n",
    "########################################################################\n",
    "# Functions to pass the data to estimators\n",
    "def my_train_fn(my_num_epochs):\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(x_train_voc)},\n",
    "    y=np.array(y_train_voc.ravel()),\n",
    "    num_epochs=my_num_epochs,\n",
    "    shuffle=False)\n",
    "    return train_input_fn\n",
    "\n",
    "def my_dev_fn():\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(x_dev_voc)},\n",
    "    y=np.array(y_dev_voc.ravel()),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "    return test_input_fn\n",
    "\n",
    "def my_test_fn():\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(x_test_voc)},\n",
    "    y=np.array(y_test.ravel()),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "    return test_input_fn\n",
    "\n",
    "def my_initializer(shape=None, dtype=tf.float32, partition_info=None):\n",
    "    assert dtype is tf.float32\n",
    "    return embedding_matrix.astype(np.float32)\n",
    "\n",
    "all_classifiers = {}\n",
    "def train_and_eval(classifier,my_epochs,my_steps):\n",
    "    all_classifiers[classifier.model_dir] = classifier\n",
    "    classifier.train(input_fn=my_train_fn(my_epochs), steps= my_steps)\n",
    "    eval_results = classifier.evaluate(input_fn=my_dev_fn(), steps= my_steps)\n",
    "    print('Eval Accuracy is ')\n",
    "    print(eval_results)\n",
    "    dev_results = classifier.predict(input_fn=my_dev_fn())\n",
    "    predictions=[]\n",
    "    for pred in dev_results:\n",
    "        predictions.append(pred)\n",
    "    print(classification_report(y_dev_voc, pd.DataFrame(predictions)))\n",
    "    print(confusion_matrix(y_dev_voc, pd.DataFrame(predictions)))\n",
    "    \n",
    "    print('################################################################')\n",
    "    print(' ')\n",
    "    print(\"Attention: This result is on test data\")\n",
    "    test_accu = classifier.evaluate(input_fn=my_test_fn(), steps= my_steps)\n",
    "    print('Test Accuracy is ')\n",
    "    print(test_accu)\n",
    "    test_results = classifier.predict(input_fn=my_test_fn())\n",
    "    test_predictions=[]\n",
    "    for pred in test_results:\n",
    "        test_predictions.append(pred)\n",
    "    print(classification_report(y_test, pd.DataFrame(test_predictions)))\n",
    "    print(confusion_matrix(y_test, pd.DataFrame(test_predictions)))\n",
    "\n",
    "\n",
    "# Building feature matrix to inject estimator shape=(3,)\n",
    "feature_x = tf.feature_column.numeric_column(\"x\", shape=x_train_voc.shape)\n",
    "# feature_x = tf.feature_column.numeric_column(\"x\", shape=(x_train_voc.shape[1],))\n",
    "feature_columns = [feature_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) DNN based custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_steps\n",
    "# my_steps=(x_train_voc.shape[0])/my_batch_size\n",
    "# my_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_device_fn': None, '_task_id': 0, '_master': '', '_train_distribute': None, '_service': None, '_num_worker_replicas': 1, '_eval_distribute': None, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_evaluation_master': '', '_save_summary_steps': 100, '_model_dir': '/home/jiv/TF/tmpy4i6ym3p/dnn', '_save_checkpoints_steps': None, '_experimental_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9318080eb8>, '_tf_random_seed': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_is_chief': True}\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-19-23ef3c4675be>:13: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-23ef3c4675be>:19: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2507381, step = 0\n",
      "INFO:tensorflow:global_step/sec: 277.876\n",
      "INFO:tensorflow:loss = 0.7413031, step = 100 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.504\n",
      "INFO:tensorflow:loss = 0.640269, step = 200 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.632\n",
      "INFO:tensorflow:loss = 0.4371779, step = 300 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.065\n",
      "INFO:tensorflow:loss = 0.44598383, step = 400 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.401\n",
      "INFO:tensorflow:loss = 0.47245687, step = 500 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.694\n",
      "INFO:tensorflow:loss = 0.5480248, step = 600 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.702\n",
      "INFO:tensorflow:loss = 0.4726755, step = 700 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.478\n",
      "INFO:tensorflow:loss = 0.41389525, step = 800 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.463\n",
      "INFO:tensorflow:loss = 0.3730409, step = 900 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.54\n",
      "INFO:tensorflow:loss = 0.4007641, step = 1000 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.983\n",
      "INFO:tensorflow:loss = 0.36229396, step = 1100 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.559\n",
      "INFO:tensorflow:loss = 0.31826058, step = 1200 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.356\n",
      "INFO:tensorflow:loss = 0.26605862, step = 1300 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.932\n",
      "INFO:tensorflow:loss = 0.28814927, step = 1400 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.729\n",
      "INFO:tensorflow:loss = 0.18497078, step = 1500 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.547\n",
      "INFO:tensorflow:loss = 0.24256966, step = 1600 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.922\n",
      "INFO:tensorflow:loss = 0.1838677, step = 1700 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.231\n",
      "INFO:tensorflow:loss = 0.13454023, step = 1800 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.54\n",
      "INFO:tensorflow:loss = 0.16191563, step = 1900 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.293\n",
      "INFO:tensorflow:loss = 0.17165725, step = 2000 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.019\n",
      "INFO:tensorflow:loss = 0.19175169, step = 2100 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.13\n",
      "INFO:tensorflow:loss = 0.18358345, step = 2200 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.865\n",
      "INFO:tensorflow:loss = 0.14986663, step = 2300 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.785\n",
      "INFO:tensorflow:loss = 0.18290399, step = 2400 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.096\n",
      "INFO:tensorflow:loss = 0.11970247, step = 2500 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.731\n",
      "INFO:tensorflow:loss = 0.12051532, step = 2600 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.089\n",
      "INFO:tensorflow:loss = 0.111456245, step = 2700 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.032\n",
      "INFO:tensorflow:loss = 0.11658359, step = 2800 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.421\n",
      "INFO:tensorflow:loss = 0.15304974, step = 2900 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.987\n",
      "INFO:tensorflow:loss = 0.0573547, step = 3000 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.382\n",
      "INFO:tensorflow:loss = 0.102763034, step = 3100 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.817\n",
      "INFO:tensorflow:loss = 0.0980272, step = 3200 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.654\n",
      "INFO:tensorflow:loss = 0.079881676, step = 3300 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.16\n",
      "INFO:tensorflow:loss = 0.083107814, step = 3400 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.308\n",
      "INFO:tensorflow:loss = 0.07736434, step = 3500 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.527\n",
      "INFO:tensorflow:loss = 0.06320648, step = 3600 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.349\n",
      "INFO:tensorflow:loss = 0.042868458, step = 3700 (0.320 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3730 into /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.06621597.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T10:43:10Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/jiv/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-10:43:10\n",
      "INFO:tensorflow:Saving dict for global step 3730: Accuracy = 0.7594221, global_step = 3730, loss = 0.7721328\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3730: /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt-3730\n",
      "Eval Accuracy is \n",
      "{'loss': 0.7721328, 'Accuracy': 0.7594221, 'global_step': 3730}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66        37\n",
      "           1       0.78      0.81      0.80       682\n",
      "           2       0.72      0.62      0.66       190\n",
      "           3       0.75      0.75      0.75       683\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1592\n",
      "   macro avg       0.76      0.69      0.72      1592\n",
      "weighted avg       0.76      0.76      0.76      1592\n",
      "\n",
      "[[ 21   4   0  12]\n",
      " [  2 555   9 116]\n",
      " [  0  25 118  47]\n",
      " [  4 126  38 515]]\n",
      "################################################################\n",
      " \n",
      "Attention: This result is on test data\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T10:43:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-10:43:11\n",
      "INFO:tensorflow:Saving dict for global step 3730: Accuracy = 0.7649123, global_step = 3730, loss = 0.7034913\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3730: /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt-3730\n",
      "Test Accuracy is \n",
      "{'loss': 0.7034913, 'Accuracy': 0.7649123, 'global_step': 3730}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/dnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63        54\n",
      "           1       0.81      0.79      0.80       860\n",
      "           2       0.68      0.67      0.67       228\n",
      "           3       0.75      0.78      0.76       853\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1995\n",
      "   macro avg       0.74      0.70      0.72      1995\n",
      "weighted avg       0.77      0.76      0.76      1995\n",
      "\n",
      "[[ 30   6   0  18]\n",
      " [  0 680  24 156]\n",
      " [  0  24 152  52]\n",
      " [ 11 129  49 664]]\n"
     ]
    }
   ],
   "source": [
    "params = {'embedding_initializer': my_initializer}\n",
    "# my_steps=2000\n",
    "# params['embedding_initializer']\n",
    "def dnn_model_fn(\n",
    "    features, # This is batch_features from input_fn\n",
    "    labels,   # This is batch_labels from input_fn\n",
    "    mode,params):    # And instance of tf.estimator.ModeKeys, see below\n",
    "    input_layer = tf.contrib.layers.embed_sequence(ids=features[\"x\"], embed_dim=size,vocab_size=VOC_size,\n",
    "                                                   initializer=params['embedding_initializer'],\n",
    "                                                   trainable=True)\n",
    "    #######################################################################################\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer, rate=0.2, training=training)\n",
    "#     pool = tf.reduce_max(input_tensor=input_layer, axis=1)\n",
    "#     print(input_layer.shape.dims)\n",
    "    flat = tf.contrib.layers.flatten(dropout_emb)\n",
    "#     print(flat.shape.dims)\n",
    "\n",
    "    h1 = tf.layers.dense(inputs=flat, units= 500, activation=tf.nn.relu)\n",
    "#     h2 = tf.layers.dense(inputs=h1, units=400, activation=tf.nn.relu)\n",
    "#     h3 = tf.layers.dense(inputs=h2, units=100, activation=tf.nn.relu)\n",
    "#     print(h1.shape.dims)\n",
    "#     h2 = tf.layers.dense(inputs=h1, units=100, activation=tf.nn.relu)\n",
    "#     print(h2.shape.dims)\n",
    "    logits = tf.layers.dense(inputs=h1, units=4)\n",
    "    ######################################################################################\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        accuracy = tf.metrics.accuracy(labels, y_pred_cls)\n",
    "#         accuracy = tf.metrics.mean_per_class_accuracy(labels, y_pred_cls,num_classes=4)\n",
    "        \n",
    "        metrics = \\\n",
    "        {\n",
    "            \"Accuracy\": accuracy\n",
    "\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            tf.summary.scalar('Train_accuracy', accuracy[1])\n",
    "  \n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "        \n",
    "    return spec\n",
    "dnn_classifier = tf.estimator.Estimator(model_fn=dnn_model_fn,params=params,\n",
    "                                        model_dir=os.path.join(model_dir, 'dnn'),)\n",
    "train_and_eval(dnn_classifier,my_num_epochs,my_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) CNN based custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_device_fn': None, '_task_id': 0, '_master': '', '_train_distribute': None, '_service': None, '_num_worker_replicas': 1, '_eval_distribute': None, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_evaluation_master': '', '_save_summary_steps': 100, '_model_dir': '/home/jiv/TF/tmpy4i6ym3p/cnn', '_save_checkpoints_steps': None, '_experimental_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f933d5f3c18>, '_tf_random_seed': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_is_chief': True}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "dropout_emb layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "WARNING:tensorflow:From <ipython-input-20-6eef3d486e11>:13: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv1d instead.\n",
      "conv layer\n",
      "[Dimension(None), Dimension(2), Dimension(150)]\n",
      "WARNING:tensorflow:From <ipython-input-20-6eef3d486e11>:16: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling1d instead.\n",
      "pool layer\n",
      "[Dimension(None), Dimension(1), Dimension(150)]\n",
      "flat layer\n",
      "[Dimension(None), Dimension(150)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4453278, step = 0\n",
      "INFO:tensorflow:global_step/sec: 202.873\n",
      "INFO:tensorflow:loss = 0.56812096, step = 100 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.464\n",
      "INFO:tensorflow:loss = 0.5152132, step = 200 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.344\n",
      "INFO:tensorflow:loss = 0.40706474, step = 300 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.791\n",
      "INFO:tensorflow:loss = 0.41154355, step = 400 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.028\n",
      "INFO:tensorflow:loss = 0.46231037, step = 500 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.122\n",
      "INFO:tensorflow:loss = 0.42599756, step = 600 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.7\n",
      "INFO:tensorflow:loss = 0.3893666, step = 700 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.238\n",
      "INFO:tensorflow:loss = 0.32057595, step = 800 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.82\n",
      "INFO:tensorflow:loss = 0.33584398, step = 900 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.667\n",
      "INFO:tensorflow:loss = 0.37382883, step = 1000 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.514\n",
      "INFO:tensorflow:loss = 0.31375706, step = 1100 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.728\n",
      "INFO:tensorflow:loss = 0.23165157, step = 1200 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.46\n",
      "INFO:tensorflow:loss = 0.22328612, step = 1300 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.444\n",
      "INFO:tensorflow:loss = 0.1936611, step = 1400 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.537\n",
      "INFO:tensorflow:loss = 0.16194025, step = 1500 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.566\n",
      "INFO:tensorflow:loss = 0.1660493, step = 1600 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.418\n",
      "INFO:tensorflow:loss = 0.14600867, step = 1700 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.937\n",
      "INFO:tensorflow:loss = 0.09771145, step = 1800 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.421\n",
      "INFO:tensorflow:loss = 0.107135564, step = 1900 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.065\n",
      "INFO:tensorflow:loss = 0.14847079, step = 2000 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.866\n",
      "INFO:tensorflow:loss = 0.13538618, step = 2100 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.3\n",
      "INFO:tensorflow:loss = 0.12697929, step = 2200 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.906\n",
      "INFO:tensorflow:loss = 0.1432502, step = 2300 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.29\n",
      "INFO:tensorflow:loss = 0.123542234, step = 2400 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.369\n",
      "INFO:tensorflow:loss = 0.106774025, step = 2500 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.149\n",
      "INFO:tensorflow:loss = 0.10183422, step = 2600 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.656\n",
      "INFO:tensorflow:loss = 0.07991673, step = 2700 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.146\n",
      "INFO:tensorflow:loss = 0.05550304, step = 2800 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.944\n",
      "INFO:tensorflow:loss = 0.09942102, step = 2900 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.538\n",
      "INFO:tensorflow:loss = 0.054488994, step = 3000 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.462\n",
      "INFO:tensorflow:loss = 0.06606486, step = 3100 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.814\n",
      "INFO:tensorflow:loss = 0.07955245, step = 3200 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.652\n",
      "INFO:tensorflow:loss = 0.052813493, step = 3300 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.072\n",
      "INFO:tensorflow:loss = 0.042919464, step = 3400 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.329\n",
      "INFO:tensorflow:loss = 0.04788219, step = 3500 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.273\n",
      "INFO:tensorflow:loss = 0.08206902, step = 3600 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.223\n",
      "INFO:tensorflow:loss = 0.041881442, step = 3700 (0.424 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3730 into /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.041157436.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "dropout_emb layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "conv layer\n",
      "[Dimension(None), Dimension(2), Dimension(150)]\n",
      "pool layer\n",
      "[Dimension(None), Dimension(1), Dimension(150)]\n",
      "flat layer\n",
      "[Dimension(None), Dimension(150)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T10:43:33Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-10:43:33\n",
      "INFO:tensorflow:Saving dict for global step 3730: Accuracy = 0.7663317, global_step = 3730, loss = 0.72827536\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3730: /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt-3730\n",
      "Eval Accuracy is \n",
      "{'loss': 0.72827536, 'Accuracy': 0.7663317, 'global_step': 3730}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "dropout_emb layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "conv layer\n",
      "[Dimension(None), Dimension(2), Dimension(150)]\n",
      "pool layer\n",
      "[Dimension(None), Dimension(1), Dimension(150)]\n",
      "flat layer\n",
      "[Dimension(None), Dimension(150)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67        37\n",
      "           1       0.76      0.85      0.80       682\n",
      "           2       0.75      0.61      0.67       190\n",
      "           3       0.77      0.74      0.75       683\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1592\n",
      "   macro avg       0.77      0.69      0.72      1592\n",
      "weighted avg       0.77      0.77      0.76      1592\n",
      "\n",
      "[[ 21   6   0  10]\n",
      " [  2 579  10  91]\n",
      " [  0  24 116  50]\n",
      " [  3 148  28 504]]\n",
      "################################################################\n",
      " \n",
      "Attention: This result is on test data\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "dropout_emb layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "conv layer\n",
      "[Dimension(None), Dimension(2), Dimension(150)]\n",
      "pool layer\n",
      "[Dimension(None), Dimension(1), Dimension(150)]\n",
      "flat layer\n",
      "[Dimension(None), Dimension(150)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T10:43:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-10:43:34\n",
      "INFO:tensorflow:Saving dict for global step 3730: Accuracy = 0.76842105, global_step = 3730, loss = 0.70571625\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3730: /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt-3730\n",
      "Test Accuracy is \n",
      "{'loss': 0.70571625, 'Accuracy': 0.76842105, 'global_step': 3730}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "dropout_emb layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "conv layer\n",
      "[Dimension(None), Dimension(2), Dimension(150)]\n",
      "pool layer\n",
      "[Dimension(None), Dimension(1), Dimension(150)]\n",
      "flat layer\n",
      "[Dimension(None), Dimension(150)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/cnn/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.56      0.65        54\n",
      "           1       0.79      0.82      0.81       860\n",
      "           2       0.71      0.64      0.67       228\n",
      "           3       0.76      0.76      0.76       853\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1995\n",
      "   macro avg       0.76      0.70      0.72      1995\n",
      "weighted avg       0.77      0.77      0.77      1995\n",
      "\n",
      "[[ 30   9   0  15]\n",
      " [  0 708  17 135]\n",
      " [  0  24 146  58]\n",
      " [  8 154  42 649]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'embedding_initializer': my_initializer}\n",
    "def cnn_model_fn(features, labels, mode, params):\n",
    "       \n",
    "    input_layer = tf.contrib.layers.embed_sequence(ids=features[\"x\"], embed_dim=size,vocab_size=VOC_size,\n",
    "                                                   initializer=params['embedding_initializer'],\n",
    "                                                   trainable=True)\n",
    "    #######################################################################################\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer, rate=0.2, training=training)\n",
    "    print('dropout_emb layer')\n",
    "    print(input_layer.shape.dims)\n",
    "    conv = tf.layers.conv1d( inputs=dropout_emb,filters=150,kernel_size=25,padding=\"same\", activation=tf.nn.relu)\n",
    "    print('conv layer')\n",
    "    print(conv.shape.dims)\n",
    "    pool = tf.layers.max_pooling1d(inputs = conv, pool_size = 2, strides = 1)\n",
    "    print('pool layer')\n",
    "    print(pool.shape.dims)\n",
    "    flat = tf.contrib.layers.flatten(pool)\n",
    "    print('flat layer')\n",
    "    print(flat.shape.dims)\n",
    "#     hidden = tf.layers.dense(inputs=flat, units = 40, activation=tf.nn.relu)\n",
    "#     dropout_hidden = tf.layers.dropout(inputs=hidden,rate=0.2,training=training)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=flat , units=4)\n",
    "    ######################################################################################\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        accuracy = tf.metrics.accuracy(labels, y_pred_cls)\n",
    "#         accuracy = tf.metrics.mean_per_class_accuracy(labels, y_pred_cls,num_classes=4)\n",
    "        \n",
    "        metrics = \\\n",
    "        {\n",
    "            \"Accuracy\": accuracy\n",
    "\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            tf.summary.scalar('Train_accuracy', accuracy[1])\n",
    "  \n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "        \n",
    "    return spec\n",
    "\n",
    "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, params=params,\n",
    "                                        model_dir=os.path.join(model_dir, 'cnn'))\n",
    "train_and_eval(cnn_classifier,my_num_epochs,my_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) LSTM based custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_device_fn': None, '_task_id': 0, '_master': '', '_train_distribute': None, '_service': None, '_num_worker_replicas': 1, '_eval_distribute': None, '_task_type': 'worker', '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_evaluation_master': '', '_save_summary_steps': 100, '_model_dir': '/home/jiv/TF/tmpy4i6ym3p/LSTM', '_save_checkpoints_steps': None, '_experimental_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f931a208f98>, '_tf_random_seed': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_protocol': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_is_chief': True}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "input layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "WARNING:tensorflow:From <ipython-input-21-86163c878da8>:12: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-21-86163c878da8>:15: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "LSTM layer\n",
      "[Dimension(None), Dimension(100)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4073194, step = 0\n",
      "INFO:tensorflow:global_step/sec: 146.883\n",
      "INFO:tensorflow:loss = 0.84181553, step = 100 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.811\n",
      "INFO:tensorflow:loss = 0.8021416, step = 200 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.422\n",
      "INFO:tensorflow:loss = 0.65115726, step = 300 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.659\n",
      "INFO:tensorflow:loss = 0.6100273, step = 400 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.817\n",
      "INFO:tensorflow:loss = 0.6404693, step = 500 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.005\n",
      "INFO:tensorflow:loss = 0.6356176, step = 600 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.932\n",
      "INFO:tensorflow:loss = 0.5964928, step = 700 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.011\n",
      "INFO:tensorflow:loss = 0.54079276, step = 800 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.364\n",
      "INFO:tensorflow:loss = 0.54027045, step = 900 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.795\n",
      "INFO:tensorflow:loss = 0.56935513, step = 1000 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.685\n",
      "INFO:tensorflow:loss = 0.5337788, step = 1100 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.772\n",
      "INFO:tensorflow:loss = 0.46356958, step = 1200 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.332\n",
      "INFO:tensorflow:loss = 0.38523024, step = 1300 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.38\n",
      "INFO:tensorflow:loss = 0.3823961, step = 1400 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.359\n",
      "INFO:tensorflow:loss = 0.3691423, step = 1500 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.757\n",
      "INFO:tensorflow:loss = 0.36828017, step = 1600 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.302\n",
      "INFO:tensorflow:loss = 0.2950531, step = 1700 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.506\n",
      "INFO:tensorflow:loss = 0.25024015, step = 1800 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.603\n",
      "INFO:tensorflow:loss = 0.2543179, step = 1900 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.917\n",
      "INFO:tensorflow:loss = 0.28403696, step = 2000 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.167\n",
      "INFO:tensorflow:loss = 0.3272512, step = 2100 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.896\n",
      "INFO:tensorflow:loss = 0.31483465, step = 2200 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.309\n",
      "INFO:tensorflow:loss = 0.2958345, step = 2300 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.188\n",
      "INFO:tensorflow:loss = 0.26628962, step = 2400 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.49\n",
      "INFO:tensorflow:loss = 0.26908892, step = 2500 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.809\n",
      "INFO:tensorflow:loss = 0.20824769, step = 2600 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.162\n",
      "INFO:tensorflow:loss = 0.24490298, step = 2700 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.987\n",
      "INFO:tensorflow:loss = 0.22521242, step = 2800 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.761\n",
      "INFO:tensorflow:loss = 0.2095168, step = 2900 (0.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.573\n",
      "INFO:tensorflow:loss = 0.1369727, step = 3000 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.584\n",
      "INFO:tensorflow:loss = 0.16859283, step = 3100 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.203\n",
      "INFO:tensorflow:loss = 0.1803838, step = 3200 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.533\n",
      "INFO:tensorflow:loss = 0.15399574, step = 3300 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.549\n",
      "INFO:tensorflow:loss = 0.16407195, step = 3400 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.481\n",
      "INFO:tensorflow:loss = 0.14867842, step = 3500 (0.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.034\n",
      "INFO:tensorflow:loss = 0.15247132, step = 3600 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.638\n",
      "INFO:tensorflow:loss = 0.124228254, step = 3700 (0.579 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3730 into /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.12666915.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "input layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "LSTM layer\n",
      "[Dimension(None), Dimension(100)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T10:44:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-10:44:00\n",
      "INFO:tensorflow:Saving dict for global step 3730: accuracy = 0.7669598, global_step = 3730, loss = 0.6892071\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3730: /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt-3730\n",
      "Eval Accuracy is \n",
      "{'loss': 0.6892071, 'accuracy': 0.7669598, 'global_step': 3730}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "input layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "LSTM layer\n",
      "[Dimension(None), Dimension(100)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.51      0.61        37\n",
      "           1       0.78      0.83      0.81       682\n",
      "           2       0.71      0.62      0.66       190\n",
      "           3       0.77      0.76      0.76       683\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1592\n",
      "   macro avg       0.75      0.68      0.71      1592\n",
      "weighted avg       0.77      0.77      0.77      1592\n",
      "\n",
      "[[ 19   3   0  15]\n",
      " [  3 568  14  97]\n",
      " [  0  27 118  45]\n",
      " [  3 130  34 516]]\n",
      "################################################################\n",
      " \n",
      "Attention: This result is on test data\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "input layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "LSTM layer\n",
      "[Dimension(None), Dimension(100)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-29T10:44:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-29-10:44:01\n",
      "INFO:tensorflow:Saving dict for global step 3730: accuracy = 0.77293235, global_step = 3730, loss = 0.6159573\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3730: /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt-3730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is \n",
      "{'loss': 0.6159573, 'accuracy': 0.77293235, 'global_step': 3730}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "input layer\n",
      "[Dimension(None), Dimension(2), Dimension(350)]\n",
      "LSTM layer\n",
      "[Dimension(None), Dimension(100)]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jiv/TF/tmpy4i6ym3p/LSTM/model.ckpt-3730\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66        54\n",
      "           1       0.82      0.82      0.82       860\n",
      "           2       0.67      0.63      0.65       228\n",
      "           3       0.76      0.77      0.77       853\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1995\n",
      "   macro avg       0.75      0.70      0.72      1995\n",
      "weighted avg       0.77      0.77      0.77      1995\n",
      "\n",
      "[[ 32   5   1  16]\n",
      " [  1 705  19 135]\n",
      " [  0  23 144  61]\n",
      " [ 10 130  52 661]]\n"
     ]
    }
   ],
   "source": [
    "params = {'embedding_initializer': my_initializer}\n",
    "def LSTM_model_fn(features, labels, mode, params):\n",
    "    input_layer = tf.contrib.layers.embed_sequence(ids=features[\"x\"], embed_dim=size,vocab_size=VOC_size,\n",
    "                                              initializer=params['embedding_initializer'],\n",
    "                                              trainable=True)\n",
    "    #################################################################\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    dropout_emb = tf.layers.dropout(inputs=input_layer, rate=0.2, training=training)\n",
    "    print('input layer')\n",
    "    print(input_layer.shape.dims)\n",
    "    # create an LSTM cell of size 100\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(100)\n",
    "    \n",
    "    # create the complete LSTM\n",
    "    _, final_states = tf.nn.dynamic_rnn(lstm_cell, dropout_emb, dtype=tf.float32)\n",
    "    \n",
    "\n",
    "    # get the final hidden states of dimensionality [batch_size x sentence_size]\n",
    "    outputs = final_states.h\n",
    "    print('LSTM layer')\n",
    "    print(outputs.shape.dims)\n",
    "#     h1 = tf.layers.dense(inputs=outputs, units=50)\n",
    "#     h2= tf.layers.dense(inputs=h1, units=50)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=outputs, units=4)\n",
    "        # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "    #################################################################\n",
    "\n",
    "\n",
    "    # Softmax output of the neural network.\n",
    "    y_pred = tf.nn.softmax(logits=logits)\n",
    "    \n",
    "    # Classification output of the neural network.\n",
    "    y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "   \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # If the estimator is supposed to be in prediction-mode\n",
    "        # then use the predicted class-number that is output by\n",
    "        # the neural network. Optimization etc. is not needed.\n",
    "        spec = tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=y_pred_cls)\n",
    "    else:\n",
    "        # Otherwise the estimator is supposed to be in either\n",
    "        # training or evaluation-mode. Note that the loss-function\n",
    "        # is also required in Evaluation mode.\n",
    "        \n",
    "        # Define the loss-function to be optimized, by first\n",
    "        # calculating the cross-entropy between the output of\n",
    "        # the neural network and the true labels for the input data.\n",
    "        # This gives the cross-entropy for each image in the batch.\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                       logits=logits)\n",
    "\n",
    "        # Reduce the cross-entropy batch-tensor to a single number\n",
    "        # which can be used in optimization of the neural network.\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "        # Define the optimizer for improving the neural network.\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "        # Get the TensorFlow op for doing a single optimization step.\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "        # Define the evaluation metrics,\n",
    "        # in this case the classification accuracy.\n",
    "        accuracy=tf.metrics.accuracy(labels, y_pred_cls)\n",
    "        metrics = \\\n",
    "        {\n",
    "            \"accuracy\": accuracy\n",
    "    \n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            tf.summary.scalar('Train_accuracy', accuracy[1])\n",
    "\n",
    "        # Wrap all of this in an EstimatorSpec.\n",
    "        spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "            eval_metric_ops=metrics)\n",
    "        \n",
    "    return spec\n",
    "\n",
    "LSTM_classifier = tf.estimator.Estimator(model_fn=LSTM_model_fn,params=params,\n",
    "                                          model_dir=os.path.join(model_dir, 'LSTM'))\n",
    "train_and_eval(LSTM_classifier,my_num_epochs,my_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15041255278225040292\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9351469408927553617\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13249576032491219311\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17099725316326666415\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10813738189\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11998964085657888121\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10811247821\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1417010495798846365\n",
      "physical_device_desc: \"device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = '../LSTM_error' \n",
    "# raw=[]  \n",
    "# with open(filepatah) as fp:  \n",
    "#     line = fp.readline()\n",
    "#     cnt = 0\n",
    "#     while line:\n",
    "#         tmp=[]\n",
    "#         for word in line.split():\n",
    "#             tmp.append(word)\n",
    "#         raw.append(tmp)\n",
    "#         line = fp.readline()\n",
    "#         cnt += 1\n",
    "# print('No of lines in corpus are '+ str(cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8bf871822d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'T'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
     ]
    }
   ],
   "source": [
    "l=0\n",
    "for i in range(0,len(raw)):\n",
    "    if raw[i][2]=='T' and raw[i][3]=='A':\n",
    "        print(raw[i])\n",
    "        l=l+1\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data=pd.DataFrame(raw)\n",
    "# # input_data.head()\n",
    "# data=[input_data.iloc[:,2],input_data.iloc[:,3]] \n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import alluvial\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm\n",
    "# import numpy as np\n",
    "\n",
    "# # Generating the input_data:\n",
    "# seed=7\n",
    "# np.random.seed(seed)\n",
    "# def rand_letter(num): return chr(ord('A')+int(num*np.random.rand()))\n",
    "# input_data = [[raw[i][2], raw[i][3]] for i in range(0,len(raw))]\n",
    "# # input_data = [[rand_letter(15), rand_letter(5)*2] for _ in range(50)]\n",
    "# # input_data=[raw[:,2],raw[:,3]]\n",
    "# # Plotting:\n",
    "# cmap = matplotlib.cm.get_cmap('jet')\n",
    "# ax = plot(\n",
    "#     input_data,  alpha=0.8, color_side=0, rand_seed=None, figsize=(7,5),\n",
    "#     disp_width=False, wdisp_sep=' '*2, cmap=cmap, fontname='Monospace',\n",
    "#     labels=('True class', 'predicted class'),v_gap_frac=0.09,h_gap_frac=0.05,  label_shift=4)\n",
    "# ax.set_title('Misclassification flow', fontsize=1, fontname='Monospace')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results = LSTM_classifier.predict(input_fn=my_test_fn())\n",
    "# test_predictions=[]\n",
    "# for pred in test_results:\n",
    "#     test_predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm\n",
    "# import numpy as np\n",
    "\n",
    "# # Generating the input_data:\n",
    "# seed=7\n",
    "# np.random.seed(seed)\n",
    "# def rand_letter(num): return chr(ord('A')+int(num*np.random.rand()))\n",
    "\n",
    "# # input_data = [[rand_letter(15), rand_letter(5)*2] for _ in range(50)]\n",
    "# input_data = [[raw[i][2], raw[i][3]] for i in range(0,len(raw))]\n",
    "# # Plotting:\n",
    "# cmap = matplotlib.cm.get_cmap('jet')\n",
    "# ax = plot(\n",
    "#     input_data,  alpha=0.8, color_side=0,rand_seed=1, figsize=(7,5),\n",
    "#     disp_width=False, wdisp_sep=1*' ',v_gap_frac=0.09,h_gap_frac=0.1, cmap=None, fontname='Monospace',\n",
    "#     labels=('', ''),  label_shift=2,width_in=True)\n",
    "# ax.set_title('', fontsize=1, fontname='Monospace')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "e = [[33,4,0,17],\n",
    "     [0,707,20,133],\n",
    "     [0,26,148,54],\n",
    "     [8,131,44,670]]      \n",
    "for row in range(4):\n",
    "    e[row] /= np.sum(e[row])\n",
    "df_cm = pd.DataFrame(e,columns=['A','B','D','T'])\n",
    "df_cm.index=['A','B','D','T']\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.25)#for label size\n",
    "sn.heatmap(df_cm, annot=True,center= 1,annot_kws={\"size\": 16})# font size\n",
    "plt.xlabel('Predicted Classes',fontsize=14)\n",
    "plt.ylabel('Ground Truth Classes',fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
